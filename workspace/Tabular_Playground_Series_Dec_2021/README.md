# [Tabular Playground Series - Dec 2021](https://www.kaggle.com/c/tabular-playground-series-dec-2021)
## 内容
- 不均衡問題を持つテーブルデータによる多クラス分類(7クラス)  
- 評価関数はAccuracy．
- Trainデータ数は4,000,000．詳細は下記の通り．  
    Cover_Type1: 1,468,136  
    Cover_Type2: 2,262,087  
    Cover_Type3: 195,712  
    Cover_Type4: 377  
    Cover_Type5: 1  
    Cover_Type6: 11,426  
    Cover_Type7: 62,261  
- Testデータ数は1,000,000．

## やったこと
1. 不均衡問題があるので，Cover_Type4に合わせてダウンサンプリングを行った．サンプリングはランダムとした．
1. 一部0-1のバイナリ変数となっていたため，それらを主成分分析により連続変数に変換した(MCAを使わなかった理由は，データ数が多すぎて処理できなかったからである)．
1. あとは標準化などの一般的な前処理を行った．
1. それぞれの機械学習モデル(LightGBM，RF，非線形SVM)で交差検証を行い，アンサンブル学習を行った(アンサンブルは単純な多数決)．

## 結果
Accuracy: 0.88430  
あんま高くないね  

## 原因・反省点
1. 不均衡データということでデータ数を減らしすぎた．というのも，Testデータ数が多いので，少しでも空間を密にしたうえで識別境界を引く必要があった．
1. 空間を密にするために，特徴量選択をすべきだった？
1. TrainデータとTestデータの各説明変数の分布を見ることで，Testデータの目的変数の傾向などを調べるべきだった．そこからストラテジーの決定をしても良かったかも．
1. また，今回の評価関数がAccuracyだったので，とりあえずCover_Type1とCover_Type2の分類に注力すべきだった．なので，異常検知問題としてCover_Type1,2とそれ以外に分類し，そこから各々の分類をすべきだった．
1. データの圧縮手法とか使うべきだった？容量デカすぎて使いたい手法が使えなかった．軽く調べた感じ，なんか圧縮して良い感じにするやり方があるらしいので，それを調べてみる．